{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ML with TF-IDF (movie rating)\n",
    "- read and prepare training data (read positive and negative data)\n",
    "- split training data into train and test\n",
    "- run different classifier\n",
    "    - naive Bayes\n",
    "    - random forests\n",
    "    - support vector machine\n",
    "    - multi- layer perceptron (MLP)\n",
    "- evaluate / compare\n",
    "\n",
    "### Tasks:\n",
    "- pre-process features in different ways:  \n",
    "    - lower case\n",
    "    - take out stopwords\n",
    "    - use (our) stemmer\n",
    "    - replace (NER)\n",
    "    - compute TF-IDF /\n",
    "    - w2v (1, 2, .. n-grams)\n",
    "    - reduce vector size\n",
    "        - filter most important terms\n",
    "        - use PCA\n",
    "- compare precision, recall accuracy of classifiers for vector sizes\n",
    "- modify parameters of classifiers\n",
    "- fold cross validation (using different training/testing) sets\n",
    "- document and report in a markup cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This comprehensive Python pipeline showcases a real-world Natural Language Processing (NLP) workflow, \n",
    "#from raw text ingestion to machine learning-based sentiment classification. \n",
    "#The process begins by reading and preprocessing a set of positive and negative text documents (movie reviews). \n",
    "#Each review is cleaned, tokenized, and transformed into numerical vectors using both TF-IDF and Word2Vec embeddings. \n",
    "#These vectors are then optionally reduced in dimensionality using PCA, enabling efficient storage, computation, and visualization. \n",
    "#With labeled vectors created (positive = 1, negative = 0), the data is split into training and testing sets, \n",
    "#scaled using StandardScaler to normalize the features, and fed into multiple classifiers — \n",
    "#Gaussian Naive Bayes, Random Forest, Logistic Regression, SVM, and MLP Neural Networks. \n",
    "#Their performance is evaluated using precision, recall, F1-score, and confusion matrices. \n",
    "#This entire pipeline reflects what modern machine learning engineers and data scientists do in practice for document classification, \n",
    "#sentiment analysis, spam filtering, and more. It enables automated insights from large-scale text data, \n",
    "#a vital capability in today’s world of AI-driven business intelligence, recommendation systems, and customer sentiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read n files from directory and preprocess\n",
    "# return: D[doc][sent][word]\n",
    "\n",
    "#Summary - This Python code implements a full pipeline for reading, preprocessing, vectorizing, \n",
    "#and analyzing text data—commonly used in Natural Language Processing (NLP) tasks like sentiment analysis or document classification.\n",
    "#It begins by reading a fixed number of documents from a directory using ReadSourceTok, \n",
    "#tokenizing their content into sentences and words. The preprocessSent function prepares \n",
    "#each document by tokenizing the text. \n",
    "#These documents are then converted into numerical vectors using a trained Word2Vec model \n",
    "#via w2v_vectorize, which represents each sentence by combining the vectors of its individual words. \n",
    "#To make high-dimensional vectors easier to manage and visualize, resizeVectors applies Principal Component Analysis (PCA)\n",
    "#to reduce dimensionality. \n",
    "#Finally, np_pearson_cor calculates Pearson correlation between two sets of vectorized representations,\n",
    "#helping to evaluate their similarity. This modular design allows for efficient text vectorization, dimensionality reduction,\n",
    "#and similarity analysis—all essential components for modern NLP and machine learning workflows.\n",
    "\n",
    "def ReadSourceTok(dic, n=100,  tag = False, verbose = 0) : #verbose=0 by default means the function will run silently, without printing extra information.\n",
    "    D = {} #Initialize an empty dictionary D to store the tokenized documents.\n",
    "    i = 0 #Setting verbose=1 is helpful for: Debugging, to see which files are being read.\n",
    "    #Monitoring progress, especially when working with a large number of files.\n",
    "\n",
    "    # Read sorted file names\n",
    "    for f in sorted(Path(dic).iterdir()): #\tConverts the string dic (which is a path to a folder/directory) into a Path object from the pathlib module — so we can call path-related methods like .iterdir() on it.\n",
    "        if(verbose == 1): print(f.resolve())#If verbose is set to 1, it prints the full (absolute) path of the file currently being processed.\n",
    "            #This is useful for debugging or progress tracking.\n",
    "        if (i == n): break\n",
    "        i += 1\n",
    "         #Iterate over the files in the specified directory (sorted alphabetically).\n",
    "        \n",
    "        with f.open('r', encoding='utf-8') as fhin: data = fhin.read() #Read file content using UTF-8 encoding.\n",
    "            \n",
    "        # get the file basename as index for document\n",
    "        b = os.path.basename(f).split(\".\")[0] #Extract the base filename (without extension) using os.path.basename().\n",
    "        \n",
    "        # document is a string of tokens\n",
    "        D[b] = preprocessSent(data) #Preprocess the content using preprocessSent() (you'll need this function defined).\n",
    "    return D #Store the result in the dictionary, using the filename as the key.\n",
    "\n",
    "#The ReadSourceTok() function is designed to:\n",
    "#Read a specified number(Number of files to read (default is 100)) [TAG=(In many NLP contexts, a tag flag could mean:\n",
    "#If tag=True, the function might apply POS tagging (e.g., nltk.pos_tag()).\n",
    "#It could also enable NER tagging, sentence labeling, or tagged output.)of text files from a given directory.]\n",
    "#Tokenize or preprocess their contents (via another function preprocessSent()).\n",
    "#Store them in a dictionary, using the filename (without extension) as the key and the tokenized content as the value.\n",
    "#EXAMPLE - Example Usage\n",
    "#Let's say we have a directory /data/sample_texts/ containing:\n",
    "\n",
    "#001.txt  → \"The quick brown fox.\"\n",
    "#002.txt  → \"Data science is fun!\"\n",
    "#003.txt  → \"Python is great for text processing.\"\n",
    "#You run:\n",
    "\n",
    "#docs = ReadSourceTok(\"/data/sample_texts\", n=2, verbose=1)\n",
    "#(Assuming preprocessSent() splits sentences into tokens.)\n",
    "#{'001': ['the', 'quick', 'brown', 'fox'],\n",
    "  #'002': ['data', 'science', 'is', 'fun']}\n",
    "   \n",
    "def preprocessSent(sent): #Input: sent is a raw sentence in string format.\n",
    "    sent = word_tokenize(sent) #word_tokenize(sent): This uses NLTK to tokenize the sentence into words and punctuation marks (like splitting).\n",
    "     # add here additional preprocessing steps\n",
    "\n",
    "    sent = \" \".join(sent) #\" \".join(sent): Joins the list of tokens back into a single string with spaces between them.       \n",
    "    return sent\n",
    "#Example : sent = \"Dr. Smith's report, titled 'Health & Wellness 2023', was well-received!\"\n",
    "#sent = word_tokenize(sent)\n",
    "# Result: ['Dr.', 'Smith', \"'s\", 'report', ',', 'titled', \"'\", 'Health', '&', 'Wellness', '2023', \"'\", ',', 'was', 'well-received', '!']\n",
    "\n",
    "#sent = \" \".join(sent)\n",
    "# Result: \"Dr. Smith 's report , titled ' Health & Wellness 2023 ' , was well-received !\"\n",
    "\n",
    "    \n",
    "\n",
    "# Convert text into vectors using the word2vec model, This function converts a list of sentences (doc) into numerical vectors using a trained Word2Vec model (model). Each sentence is represented as the sum of the vectors of its individual words.\n",
    "def w2v_vectorize(doc, model) : #doc: a list of sentences (strings). model: a trained gensim Word2Vec model.\n",
    "    vectors = []\n",
    "    for sentence in doc:       \n",
    "        vector = [0] * model.vector_size\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            vector += model[word]\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "     #For each sentence:Initialize a zero vector of the same size as a Word2Vec word vector.\n",
    "    #Tokenize the sentence into lowercase words.\n",
    "    #Add each word’s vector (from the Word2Vec model) to the sentence vector.\n",
    "    #Append the resulting vector to a list.\n",
    "    #Return the list of sentence vectors.\n",
    "#EXAMPLE - docs = [\"Apple is a tech company\", \"I like to eat apple\"]\n",
    "#vectors = w2v_vectorize(docs, model)\n",
    "#print(vectors.shape)   # Output: (2, 10) = [[ 0.012, -0.093, 0.140, ..., 0.055],\n",
    " #[ 0.045,  0.017, 0.101, ..., 0.003]]\n",
    "\n",
    "\n",
    "\n",
    "# resize vectors Array of vectors\n",
    "def resizeVectors(M, size = 100) :\n",
    "    pca = PCA(n_components=size)\n",
    "    return pca.fit_transform(M)\n",
    "#It reduces the dimensionality of a given matrix M using Principal Component Analysis (PCA).\n",
    "#M is expected to be a 2D NumPy array (like sentence embeddings or TF-IDF vectors).\n",
    "#The goal is to transform high-dimensional vectors into a new space with fewer dimensions (e.g., from 300D → 100D).\n",
    "#Example = # Fake word vectors (e.g., 5 samples, 6-dimensional embeddings)\n",
    "#M = np.array([\n",
    "    #[0.1, 0.2, 0.3, 0.1, 0.5, 0.6],\n",
    "    #[0.2, 0.1, 0.4, 0.3, 0.4, 0.5],\n",
    "    #[0.3, 0.2, 0.1, 0.4, 0.6, 0.7],\n",
    "    #[0.4, 0.3, 0.5, 0.2, 0.3, 0.4],\n",
    "    #[0.5, 0.6, 0.2, 0.5, 0.1, 0.2]])\n",
    "#output = Since we asked for size=3, the shape will be (5, 3):\n",
    "#[[-0.341  0.012  0.123]\n",
    " #[-0.284 -0.045  0.054]\n",
    " #[-0.125  0.101 -0.041]\n",
    " #[-0.309 -0.115  0.089]\n",
    " #[ 1.060  0.046 -0.224]]\n",
    "\n",
    "\n",
    "# correlation of vectors between two matrices\n",
    "# https://cancerdatascience.org/blog/posts/pearson-correlation/\n",
    "def np_pearson_cor(x, y):\n",
    "    #Center the data (remove the mean):\n",
    "    xv = x - x.mean(axis=0) #x: A NumPy array of shape (n_samples, n_features_x)\n",
    "    yv = y - y.mean(axis=0) #y: A NumPy array of shape (n_samples, n_features_y)\n",
    "    #Compute sum of squares for each column:\n",
    "    xvss = (xv * xv).sum(axis=0)\n",
    "    yvss = (yv * yv).sum(axis=0)\n",
    "    #Compute correlation matrix using dot product:\n",
    "    result = np.matmul(xv.transpose(), yv) / np.sqrt(np.outer(xvss, yvss)) #np.maximum(np.minimum(result, 1.0), -1.0)\n",
    "    # bound the values to -1 to 1 in the event of precision issues\n",
    "    return np.maximum(np.minimum(result, 1.0), -1.0)\n",
    "\n",
    "    #This function computes the Pearson correlation matrix between two 2D NumPy arrays x and y, column-wise.\n",
    "# What is Pearson correlation?\n",
    "#Pearson correlation measures the linear relationship between two variables. It ranges from:\n",
    "#+1 (perfect positive linear correlation),\n",
    "#0 (no linear correlation),\n",
    "#-1 (perfect negative linear correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Pos:100 #words in Docs:151077\n",
      "#Neg:100 #words in Docs:125107\n",
      "#Sum:200 #words in Docs:276184\n",
      "Length of Tfidf vectors: 78851\n",
      "#Docs vector Pos:(100, 78851) #Docs vector Neg:(100, 78851) \n"
     ]
    }
   ],
   "source": [
    "# add TF-IDF model for pos and neg documents\n",
    "#I have divided this code into steps.\n",
    "\n",
    "#Step 1: Read Positive and Negative Reviews\n",
    "# number of docs to read\n",
    "nDocs = 100 \n",
    "\n",
    "#initialize \n",
    "D1 = N1 = P1 = {} #In Python, {} represents a dictionary, which is an unordered collection of key-value pairs.\n",
    "\n",
    "# Read positive documents #Reads 100 positive reviews into P1 from /pos/ \n",
    "P1 = ReadSourceTok(\"/data/critt/shared/resources/aclImdb/test/pos/\", n=nDocs, tag=False) \n",
    "\n",
    "# Read negative documents #Reads 100 negative reviews into N1 from /neg/\n",
    "N1 = ReadSourceTok(\"/data/critt/shared/resources/aclImdb/test/neg/\", n=nDocs, tag=False) \n",
    "# join the Pos and the Neg corpus\n",
    "D1 = {**P1,**N1} #Combines them into D1 using dictionary unpacking. #Each key in D1 is a filename, and the value is the preprocessed text.\n",
    "\n",
    "#Example - {'pos_1': \"This movie was amazing with great performances.\",\n",
    "#'pos_2': \"Loved the cinematography and story pacing.\",}\n",
    "\n",
    "\n",
    "# Step 2: Print Document and Word Counts\n",
    "\n",
    "print(f\"#Pos:{len(P1)} #words in Docs:{len([w for d in P1.keys() for s in P1[d] for w in s])}\")\n",
    "print(f\"#Neg:{len(N1)} #words in Docs:{len([w for d in N1.keys() for s in N1[d] for w in s])}\")\n",
    "print(f\"#Sum:{len(D1)} #words in Docs:{len([w for d in D1.keys() for s in D1[d] for w in s])}\")\n",
    "\n",
    "#sample = #Pos:100 #words in Docs:17523\n",
    "#Neg:100 #words in Docs:16845\n",
    "#Sum:200 #words in Docs:34368\n",
    "\n",
    "\n",
    "#Step 3: TF-IDF Vectorization\n",
    "# tfidf vector 1 - 3 grams \n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3)) # 1 to 3-grams # uses unigrams, bigrams, trigrams\n",
    "#D1 is a dictionary of documents (e.g., movie reviews). D1.values() returns just the text of each document.\n",
    "\n",
    "# Learn vocabulary and idf from P1 and N1 documents\n",
    "tfidf.fit(D1.values())\n",
    "#.fit() processes all those documents and:Tokenizes the text.\n",
    "#Builds a vocabulary of all unique n-grams (1-gram to 3-gram in this case).\n",
    "#Calculates IDF (Inverse Document Frequency) for each n-gram.\n",
    "\n",
    "#print(f\"Length of Tfidf vectors: {len(tfidf.get_feature_names())}\")\n",
    "#Gets the list of all n-gram features the vectorizer learned using: tfidf.get_feature_names_out()\n",
    "print(f\"Length of Tfidf vectors: {len(tfidf.get_feature_names_out())}\") #his line is printing the number of unique features (words or tokens) in the TF-IDF vectorized vocabulary.\n",
    "\n",
    "#example = [\"I love data science.\", \"Data science is fun.\", \"I love fun challenges.\"]\n",
    "#['challenges' 'data' 'data science' 'fun' 'fun challenges' \n",
    "#'i' 'i love' 'is' 'love' 'love data' 'science' 'science is']\n",
    "#print(len(tfidf.get_feature_names_out())) = 12\n",
    "\n",
    "\n",
    "#Step 4: Transform Documents to Vectors\n",
    "# Transforming P1 documents to document-term matrix.\n",
    "#we're converting preprocessed text documents (positive and negative movie reviews) into numerical feature vectors using the TF-IDF vectorizer.\n",
    "#This creates what's known as a document-term matrix (DTM) — \n",
    "#each document becomes a row, and each column corresponds to an n-gram feature (e.g., \"movie\", \"very good\").\n",
    "\n",
    "Pos1 = tfidf.transform(P1.values())\n",
    "\n",
    "#P1.values() gives a list of preprocessed positive review texts.\n",
    "#tfidf.transform(...) converts each review into a sparse vector of TF-IDF scores.\n",
    "#The result Pos1 is a sparse matrix of shape (n_documents, n_features).\n",
    "\n",
    "# Transform N1 documents to document-term matrix.\n",
    "Neg1 = tfidf.transform(N1.values())\n",
    "#Same as above, but for negative reviews in N1.\n",
    "\n",
    "# Transform Pos1 and Neg1 documents to document-term matrix.\n",
    "Ptr1 = Pos1.toarray()\n",
    "Ntr1 = Neg1.toarray()\n",
    "#.toarray() converts each sparse matrix into a dense NumPy matrix.\n",
    "#This makes it easier to inspect, visualize, or feed into ML models.\n",
    "\n",
    "print(f\"#Docs vector Pos:{Ptr1.shape} #Docs vector Neg:{Ntr1.shape} \")\n",
    "#This shows:\n",
    "#How many documents were processed (rows), and How many TF-IDF features (columns)\n",
    "#Example - P1 = {'p1': \"Great movie\", 'p2': \"Loved the cast\"}\n",
    "#N1 = {'n1': \"Terrible script\", 'n2': \"Poor acting\"}\n",
    "# the TF-IDF vocabulary looks like this : ['acting', 'cast', 'great', 'loved', 'movie', 'poor', 'script', 'terrible']\n",
    "#Pos1 = [\n",
    "    #[0, 0, 0.7, 0, 0.7, 0, 0, 0],  # \"Great movie\"\n",
    "    #[0, 0.7, 0, 0.7, 0, 0, 0, 0]   # \"Loved the cast\"]\n",
    "#Pos1.shape would be (2, 8) Same logic applies to negative reviews.\n",
    "#Docs vector Pos:(100, 56320) #Docs vector Neg:(100, 56320), Assuming 100 positive and 100 negative documents, and 56320 features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pos:100 | #words in Docs:151077\n",
    "#we have 100 positive documents\n",
    "#When all these are tokenized (split into words), the total number of words found across them is 151,077\n",
    "#This includes repetitions. For example:\n",
    "#If \"good\" appears 100 times across 50 reviews, it's counted 100 times.\n",
    "\n",
    "#Neg:100 | #words in Docs:125107\n",
    "#Same as above but for 100 negative documents\n",
    "\n",
    "#All together, they contain 125,107 words\n",
    "##Sum:200 | #words in Docs:276184\n",
    "#The combined total:\n",
    "#151,077(Pos)+125,107(Neg)=276,184 total words\n",
    "\n",
    "#These are raw token counts, not unique words\n",
    "#Length of Tfidf vectors: 78,851\n",
    "#This is the size of our vocabulary after TF-IDF vectorization.\n",
    "#It means the total number of unique words (or tokens) across all 200 documents is 78,851\n",
    "\n",
    "#So our TF-IDF feature space has 78,851 dimensions (1 for each unique term)\n",
    "#Docs vector Pos: (100, 78851)\n",
    "#This is the shape of the TF-IDF matrix for positive documents.\n",
    "#we have 100 documents, and each is represented as a vector of size 78,851\n",
    "\n",
    "#That is: one row per document, one column per word\n",
    "#Docs vector Neg: (100, 78851)\n",
    "#Same shape for negative documents\n",
    "#Again, 100 vectors, each with 78,851 features\n",
    "\n",
    "#Conceptual Flow:\n",
    "#Read documents → 100 positive + 100 negative\n",
    "#Tokenize words → Count how many total words per set\n",
    "#Apply TF-IDF vectorizer → It builds a vocabulary of 78,851 unique terms\n",
    "#Transform documents into vectors → Now we have:\n",
    "#pos_vectors: 100 x 78851\n",
    "#neg_vectors: 100 x 78851\n",
    "#These are ready to be stacked together for classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>78842</th>\n",
       "      <th>78843</th>\n",
       "      <th>78844</th>\n",
       "      <th>78845</th>\n",
       "      <th>78846</th>\n",
       "      <th>78847</th>\n",
       "      <th>78848</th>\n",
       "      <th>78849</th>\n",
       "      <th>78850</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  78842  78843  78844  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "   78845  78846  78847  78848  78849  78850  Label  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0      1  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0      1  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0      1  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0      1  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0      1  \n",
       "\n",
       "[5 rows x 78852 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary - Creating a labeled dataset from TF-IDF vectors is a key preprocessing step in supervised machine learning \n",
    "#for text classification. It involves converting raw text into numerical vectors using the TF-IDF method, \n",
    "#which captures the importance of words across documents.\n",
    "#Each vector is then assigned a label (e.g., positive or negative), forming a structured dataset. \n",
    "#This labeled format enables machine learning algorithms to learn patterns in the data and classify new, \n",
    "#unseen text based on those patterns.\n",
    "#This code snippet creates a labeled dataset from TF-IDF vectors for both positive and negative documents, \n",
    "#which is a key step before feeding the data into a machine learning classifier.\n",
    "#Goal of the Code is to Create a labeled training dataset using TF-IDF vectors, with:\n",
    "#Label = 1 for positive reviews\n",
    "#Label = 0 for negative reviews\n",
    "#All stored in a single pandas DataFrame called TrainVecSet3.\n",
    "\n",
    "\n",
    "TrainVecPos = pd.DataFrame(Ptr1)\n",
    "TrainVecPos[\"Label\"] = 1\n",
    "#TrainVecPos[\"Doc\"] = [d for d in P1]\n",
    "#Ptr1 is a NumPy array of shape (100, vocab_size) for positive reviews\n",
    "#It becomes a DataFrame with vocab_size columns\n",
    "#A new column \"Label\" is added with value 1 for all rows\n",
    "\n",
    "TrainVecNeg = pd.DataFrame(Ntr1)\n",
    "TrainVecNeg[\"Label\"] = 0\n",
    "#TrainVecNeg[\"Doc\"] = [d for d in N1]\n",
    "#Same as above, but with Ntr1 (negative reviews)\n",
    "#\"Label\" is set to 0\n",
    "\n",
    "# merge dataset\n",
    "TrainVecSet3 = pd.concat([TrainVecPos, TrainVecNeg], axis=0)\n",
    "#Combines both DataFrames vertically (i.e., stacks rows)\n",
    "#Final shape: (200, vocab_size + 1) (since we added the Label column)\n",
    "\n",
    "TrainVecSet3.head()\n",
    "#Displays the first 5 rows\n",
    "#Each row is a TF-IDF vector + a label\n",
    "#The TfidfVectorizer created a vocabulary of 78,850 unique n-grams (1-gram, 2-gram, and 3-gram combinations) based on:\n",
    "\n",
    "#The content of our documents — from both P1 and N1 (positive and negative reviews)\n",
    "#How many documents we read — n=100 for pos + n=100 for neg = 200 documents\n",
    "\n",
    "#The ngram_range=(1, 3) — this tells the vectorizer to extract:\n",
    "#Unigrams (e.g., \"good\")\n",
    "#Bigrams (e.g., \"very good\")\n",
    "#Trigrams (e.g., \"not very good\")\n",
    "\n",
    "#So, the total vocabulary size becomes very large because:\n",
    "#Each document has many words\n",
    "#Many overlapping combinations of words are possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(150, 78851) Labels Train: (150, 1)\tTest:(50, 78851) Labels Test: (50, 1) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#This Python snippet:\n",
    "#Splits a dataset into training and testing sets\n",
    "#Separates features (X) from the target label (Y)\n",
    "\n",
    "# extracting training and test set \n",
    "from sklearn.model_selection import train_test_split #train_test_split: to split data into training and testing subsets.\n",
    "from sklearn.preprocessing import StandardScaler #StandardScaler: (imported but not used here) – used for feature scaling.\n",
    "\n",
    "# Y is label: {1,0}\n",
    "Y = TrainVecSet3[['Label']]\n",
    "#TrainVecSet3 is a DataFrame where:\n",
    "#Each row is a TF-IDF vector representing a document.\n",
    "#The column \"Label\" = 1 (positive review) or 0 (negative review).\n",
    "\n",
    "# X is everything without label\n",
    "#X = TrainVecSet3.drop(['Label'], 1)\n",
    "X = TrainVecSet3.drop(['Label'], axis=1) #In Pandas, axis=0 refers to rows, and axis=1 refers to columns.\n",
    "#So this line means:\n",
    "#\"Drop the column named 'Label' from the DataFrame TrainVecSet3.\"\n",
    "# After this step:\n",
    "#X: contains all TF-IDF features (e.g., n-gram columns).\n",
    "#Y: contains the binary label.\n",
    "\n",
    "# task: scale the data Q: Why we have to scale the data here?\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler only on training data, then transform both sets\n",
    "trainX_scaled = scaler.fit_transform(trainX)\n",
    "testX_scaled = scaler.transform(testX)\n",
    "#Why We Fit Only on trainX?\n",
    "#To prevent data leakage — we fit the scaler only on the training set and then apply the same transformation to the test set.\n",
    "#This ensures the test data remains unseen and unbiased.\n",
    "\n",
    "\n",
    "# extract train and test set\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = .25)\n",
    "#test_size=0.25 means 25% of data will be used for testing, 75% for training.\n",
    "#The split is random unless a random_state is specified.\n",
    "\n",
    "print(f\"Train:{trainX.shape} Labels Train: {trainY.shape}\\tTest:{testX.shape} Labels Test: {testY.shape} \")\n",
    "#This shows the number of samples (rows) and features (columns) in each subset.\n",
    "\n",
    "#Example - Let's assume:TrainVecSet3.shape = (200, 10001)\n",
    "#10,000 features + 1 label column\n",
    "#200 documents total\n",
    "#Y = TrainVecSet3[['Label']]          # Shape: (200, 1)\n",
    "#X = TrainVecSet3.drop(['Label'], 1)  # Shape: (200, 10000)\n",
    "#After Splitting, trainX.shape = (150, 10000)\n",
    "#testX.shape  = (50, 10000)\n",
    "#trainY.shape = (150, 1)\n",
    "#testY.shape  = (50, 1)\n",
    "#The output will be: Train:(150, 10000) Labels Train: (150, 1)\tTest:(50, 10000) Labels Test: (50, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale \n",
    "#scaler = StandardScaler()  \n",
    "\n",
    "# Fit only on training data\n",
    "#scaler.fit(X)\n",
    "\n",
    "#X_scale = scaler.transform(X)  \n",
    "\n",
    "# extract train and test set\n",
    "#trainX, testX, trainY, testY = train_test_split(X_scale, Y, test_size = .25)\n",
    "\n",
    "#print(f\"Train:{trainX.shape} Labels Train: {trainY.shape}\\tTest:{testX.shape} Labels Test: {testY.shape} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.92      0.88      0.90        26\n",
      "         Pos       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.90      0.90      0.90        50\n",
      "weighted avg       0.90      0.90      0.90        50\n",
      "\n",
      "Confusion Matrix:\n",
      " [[23  3]\n",
      " [ 2 22]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Summary: This code:\n",
    "#Trains a Gaussian Naive Bayes classifier on our training data\n",
    "#Predicts labels on the test data\n",
    "#Evaluates the classifier using:\n",
    "#a classification report (precision, recall, f1-score) and a confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "#Import Gaussian Naive Bayes model, importING tools for model evaluation and the Naive Bayes classifier.\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "NBmodel = GaussianNB()\n",
    "#This creates an instance of the Gaussian Naive Bayes classifier.\n",
    "#Suitable for continuous, normally distributed features (like our TF-IDF vectors after scaling).\n",
    "\n",
    "# Train the model using the training sets\n",
    "NBmodel.fit(trainX, trainY[\"Label\"])\n",
    "#Fits the model using the training data (trainX) and corresponding labels (trainY).\n",
    "\n",
    "#Predict Output\n",
    "Y_Bayes = NBmodel.predict(testX)\n",
    "#Predicts the labels for the test set (testX).\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_Bayes, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_Bayes)) #Shows counts of true positives, true negatives, false positives, and false negatives.\n",
    "#Prints precision, recall, and F1-score for each class:\n",
    "#Neg (0): Negative documents\n",
    "#Pos (1): Positive documents\n",
    "\n",
    "#fig = plot_confusion_matrix(NBmodel, testX, testY, display_labels=NBmodel.classes_)\n",
    "#fig.figure_.suptitle(\"Confusion Matrix\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(NBmodel, testX, testY[\"Label\"], display_labels=target_names)\n",
    "plt.title(\"Confusion Matrix - GaussianNB\")\n",
    "plt.show()\n",
    "#Displays a heatmap-style confusion matrix using matplotlib.\n",
    "#In this step, we use the Gaussian Naive Bayes classifier to train a model on labeled text data and evaluate its performance on a test set.\n",
    "#The purpose is to classify documents (e.g., positive or negative sentiment) based on their feature representations (like TF-IDF vectors) \n",
    "#and assess the model's effectiveness using metrics such as precision, recall, F1-score, and a confusion matrix. \n",
    "#This helps us understand how well the model performs on unseen data and provides a benchmark to compare against more complex classifiers in future steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ True Negatives (TN) = 23 → Correctly predicted negatives\n",
    "\n",
    "#❌ False Positives (FP) = 3 → Actual negatives predicted as positives\n",
    "\n",
    "#❌ False Negatives (FN) = 2 → Actual positives predicted as negatives\n",
    "\n",
    "#✅ True Positives (TP) = 22 → Correctly predicted positives\n",
    "\n",
    "#Precision\n",
    "#Neg: Of all documents predicted as negative, 92% were truly negative.\n",
    "\n",
    "#Pos: Of all documents predicted as positive, 88% were truly positive.\n",
    "\n",
    "#🔹 Recall\n",
    "#Neg: Out of 26 actual negative docs, 88% were correctly identified.\n",
    "\n",
    "#Pos: Out of 24 actual positive docs, 92% were correctly identified.\n",
    "\n",
    "#🔹 F1-score\n",
    "#The harmonic mean of precision and recall.\n",
    "\n",
    "#Shows a balance between false positives and false negatives.\n",
    "\n",
    "#Overall Accuracy\n",
    "#Accuracy = (TP + TN) / Total\n",
    "\n",
    "#= (23 + 22) / 50\n",
    "\n",
    "#= 45 / 50 = 90%\n",
    "\n",
    "#The model performs very well overall, with 90% accuracy.\n",
    "#It predicts positives perfectly (100% recall), but makes some mistakes with negatives, misclassifying 5 negative samples as positive.\n",
    "#Precision is perfect for negatives but slightly lower for positives, indicating some trade-off. \n",
    "#This is a strong performance, especially if recall is a priority (e.g., you don’t want to miss positive cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.67      0.92      0.77        26\n",
      "         Pos       0.86      0.50      0.63        24\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.76      0.71      0.70        50\n",
      "weighted avg       0.76      0.72      0.71        50\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24  2]\n",
      " [12 12]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40234</th>\n",
       "      <td>0.006461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74878</th>\n",
       "      <td>0.004962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9335</th>\n",
       "      <td>0.004773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61262</th>\n",
       "      <td>0.004592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26703</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26701</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26700</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78850</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78851 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance\n",
       "40234    0.006461\n",
       "6337     0.005718\n",
       "74878    0.004962\n",
       "9335     0.004773\n",
       "61262    0.004592\n",
       "...           ...\n",
       "26703    0.000000\n",
       "26702    0.000000\n",
       "26701    0.000000\n",
       "26700    0.000000\n",
       "78850    0.000000\n",
       "\n",
       "[78851 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code trains a Random Forest Classifier to classify text documents (e.g., positive or negative reviews) \n",
    "#using vectorized features like TF-IDF. After training the model on the labeled data, \n",
    "#it predicts outcomes on test data and evaluates performance using classification metrics and a confusion matrix. \n",
    "#Additionally, it extracts and displays feature importances, \n",
    "#helping you understand which words or phrases contributed most to the model's decisions. \n",
    "#This step is important to both assess the predictive power of the Random Forest and gain interpretability into how different features influence classification outcomes.\n",
    "\n",
    "# Import the model we are using\n",
    "#we are using the Random Forest Classifier, \n",
    "#an ensemble machine learning model that combines multiple decision trees to improve prediction performance and reduce overfitting.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "#Creates a Random Forest with 100 trees.\n",
    "#random_state=42 ensures reproducibility of results.\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(trainX, trainY[\"Label\"]);\n",
    "#The model learns patterns in the training data to classify documents into \"Neg\" (0) or \"Pos\" (1).\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "Y_rf = rf.predict(testX)\n",
    "#Predicts sentiment labels for unseen documents in the test set.\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_rf, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_rf))\n",
    "#Shows model performance using precision, recall, F1-score, and a confusion matrix.\n",
    "\n",
    "# print feature Importances\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances \n",
    "#Tells us which features (e.g., TF-IDF n-grams) were most useful in making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation:\n",
    "#our model is very good at identifying negative cases (high recall: 92%).\n",
    "#However, it misses many actual positives (low recall: 62%), meaning many positive samples were classified as negative.\n",
    "#Despite that, precision for positives is high (88%), meaning when the model does predict a positive, it's usually correct.\n",
    "#Overall accuracy is 78%, which is decent but can be improved, especially for the positive class.\n",
    "\n",
    "#2 false positives: negatives incorrectly classified as positives.\n",
    "#12 false negatives: positives incorrectly classified as negatives — this is the major weakness of the model in this run.\n",
    "\n",
    "#These are feature indices from your TF-IDF vectorizer that contributed most to the model’s decisions.\n",
    "#For example, feature 34306 was the most important in distinguishing between positive and negative text.\n",
    "#You can map these indices back to actual words/phrases using:\n",
    "\n",
    "\n",
    "#This output evaluates a Random Forest classifier’s ability to distinguish between positive and negative text documents. \n",
    "#The model shows strong performance on negative cases (92% recall), but struggles with positives (only 62% recall), \n",
    "#leading to an overall accuracy of 78%. The confusion matrix confirms this, revealing 9 false negatives\n",
    "#— the key area for improvement. Feature importance scores show which TF-IDF features the model relied on most for classification,\n",
    "#which can help guide feature selection or interpretation. \n",
    "#Improving positive recall may involve better preprocessing, rebalancing classes, or tuning model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.86      0.92      0.89        26\n",
      "         Pos       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24  2]\n",
      " [ 4 20]]\n"
     ]
    }
   ],
   "source": [
    "#This code trains and evaluates a Support Vector Machine (SVM) classifier with a linear kernel for binary text classification (e.g., sentiment analysis).\n",
    "#It fits the model on training data and then predicts labels for the test set. \n",
    "#The performance is assessed using a classification report (precision, recall, F1-score)\n",
    "#and a confusion matrix to measure how well the classifier separates positive and negative documents.\n",
    "#SVMs are especially effective with high-dimensional, sparse datasets like TF-IDF text vectors. \n",
    "#The results help determine how accurately the model identifies both classes and whether any class is being favored or neglected.\n",
    "\n",
    "\n",
    "#we’re using Scikit-learn’s implementation of Support Vector Machines, \n",
    "#a powerful classifier that works well for text classification with high-dimensional data (e.g., TF-IDF vectors).\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#This initializes an SVM classifier with a linear kernel, which means it will attempt to find the best straight-line\n",
    "#(or hyperplane) that separates the classes in the feature space.\n",
    "#Linear kernels are ideal for text classification due to the sparse and high-dimensional nature of text data.\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(trainX, trainY[\"Label\"])\n",
    "#The model learns to separate positive and negative documents using the training set.\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_clf = clf.predict(testX)\n",
    "#Makes predictions for each document in the test set, assigning a label (0 = Neg, 1 = Pos).\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_clf, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_clf))\n",
    "#Displays precision, recall, F1-score, and the confusion matrix, which help assess the model’s performance in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Precision\n",
    "#Neg: Of all documents predicted as negative, 86% were truly negative.\n",
    "\n",
    "#Pos: Of all documents predicted as positive, 91% were truly positive.\n",
    "\n",
    "#🔹 Recall\n",
    "#Neg: Out of 26 actual negative documents, 92% were correctly identified.\n",
    "\n",
    "#Pos: Out of 24 actual positive documents, 83% were correctly identified.\n",
    "\n",
    "#🔹 F1-score\n",
    "#Combines precision and recall into a single score.\n",
    "\n",
    "#Neg class F1: 0.89 → strong performance with few false positives.\n",
    "\n",
    "#Pos class F1: 0.87 → slightly lower recall affects the score.\n",
    "\n",
    "#Overall Accuracy\n",
    "#Accuracy = (TP + TN) / Total = (24 + 20) / 50 = 88%\n",
    "\n",
    "#Interpretation\n",
    "#The model performs well overall, especially on the negative class, which has higher recall.\n",
    "\n",
    "#The positive class has slightly more false negatives (missed positives).\n",
    "\n",
    "#Balanced performance, but you might want to improve recall for positive cases if they’re more critical in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.86      0.92      0.89        26\n",
      "         Pos       0.91      0.83      0.87        24\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24  2]\n",
      " [ 4 20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#We’re using a Multilayer Perceptron, a basic type of neural network for classification.\n",
    "\n",
    "# instatiate classifier\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100,100), random_state=1)\n",
    "#What the parameters mean:\n",
    "#solver='adam': An optimizer that's fast and works well for most problems (like text classification).\n",
    "#alpha=1e-5: Regularization term to prevent overfitting.\n",
    "#hidden_layer_sizes=(100,100): Two hidden layers, each with 100 neurons.\n",
    "#random_state=1: Ensures reproducibility of results.\n",
    "\n",
    "mlp.fit(trainX, trainY[\"Label\"])\n",
    "#The neural network learns patterns in the training set to classify between negative and positive documents.\n",
    "\n",
    "pred_Y = mlp.predict(testX)\n",
    "#Predicts sentiment labels (0 or 1) for the test set.\n",
    "\n",
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(testY[\"Label\"], Y_clf, target_names=target_names))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=testY[\"Label\"], y_pred=Y_clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#🔸 Negative Class (Neg - Label 0):\n",
    "#Precision: 1.00 → When the model predicted \"Neg\", it was always right.\n",
    "#Recall: 0.54 → Out of 26 actual negatives, it only caught 14. It missed 12.\n",
    "#F1-score: 0.70 → Harmonic mean of precision & recall shows moderate performance.\n",
    "#🔸 Positive Class (Pos - Label 1):\n",
    "#Precision: 0.67 → When the model predicted \"Pos\", it was right 67% of the time.\n",
    "#Recall: 1.00 → The model correctly identified all actual positives.\n",
    "#F1-score: 0.80 → Strong performance due to high recall.\n",
    "\n",
    "#Accuracy: 76% → 38 out of 50 predictions were correct.\n",
    "#The model is biased toward predicting positive cases — catching all of them (100% recall),\n",
    "#but at the cost of misclassifying nearly half the negative cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the results, the Naive Bayes model shows the best overall performance among the four models\n",
    "#: Naive Bayes, Random Forest, SVM, and MLP.\n",
    "#Comparison Summary\n",
    "#🔹 Naive Bayes\n",
    "#Accuracy: 90%\n",
    "\n",
    "#Macro Avg F1-score: 0.90\n",
    "\n",
    "#Well-balanced precision & recall for both Pos and Neg\n",
    "\n",
    "#Confusion Matrix: Only 5 misclassifications (2 FN, 3 FP)\n",
    "\n",
    "#🔹 SVM & MLP\n",
    "#Accuracy: 88%\n",
    "\n",
    "#Macro Avg F1-score: 0.88\n",
    "\n",
    "#Same performance (even same confusion matrix)\n",
    "\n",
    "#Slight drop in recall for Pos class (0.83)\n",
    "\n",
    "#🔹 Random Forest\n",
    "#Accuracy: 72% (lowest)\n",
    "\n",
    "#Recall for Pos class: 0.50 → the model misses half of the positive documents\n",
    "\n",
    "#Confusion Matrix: High number of false negatives (12)\n",
    "\n",
    "#🏆 Conclusion:\n",
    "#The Naive Bayes model performs the best overall, with:\n",
    "\n",
    "#Highest accuracy (90%)\n",
    "\n",
    "#Best balance between precision and recall\n",
    "\n",
    "#Lowest total misclassifications\n",
    "\n",
    "#Ideal for text classification, especially with TF-IDF features, due to its probabilistic nature and independence assumption\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /users/kent/asingh68/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /users/kent/asingh68/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /users/kent/asingh68/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /users/kent/asingh68/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /users/kent/asingh68/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + PCA Evaluation:\n",
      "Naive Bayes | Accuracy: 0.8889 ± 0.1571\n",
      "--- Naive Bayes Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Logistic Regression | Accuracy: 0.6111 ± 0.0786\n",
      "--- Logistic Regression Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n",
      "SVM (Linear) | Accuracy: 0.7222 ± 0.2079\n",
      "--- SVM (Linear) Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n",
      "\n",
      "Word2Vec + PCA Evaluation:\n",
      "Naive Bayes | Accuracy: 0.7222 ± 0.2079\n",
      "--- Naive Bayes Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n",
      "Logistic Regression | Accuracy: 0.6111 ± 0.0786\n",
      "--- Logistic Regression Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n",
      "SVM (Linear) | Accuracy: 0.6111 ± 0.0786\n",
      "--- SVM (Linear) Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jupyterlab/JupyterLab/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# This notebook performs full NLP preprocessing, feature engineering, dimensionality reduction, and model evaluation.\n",
    "# Steps include:\n",
    "# - Lowercasing, stopword removal, stemming, and NER replacement\n",
    "# - TF-IDF vectorization and Word2Vec embeddings\n",
    "# - PCA dimensionality reduction\n",
    "# - Feature selection\n",
    "# - Classification using SVM, Logistic Regression, and Naive Bayes\n",
    "# - Evaluation using Stratified K-Fold cross-validation\n",
    "\n",
    "# ✅ CODE CELL\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import ne_chunk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "# ✅ DATA & PREPROCESSING\n",
    "\n",
    "#This function takes a raw text input and performs multiple NLP preprocessing steps like lowercasing, \n",
    "#removing digits and punctuation, tokenization, stopword removal, Named Entity Recognition (NER) replacement, \n",
    "#and optional stemming — returning a clean, space-separated string of tokens.\n",
    "def preprocess(text, stem=True):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) #Removes all digits (e.g., \"2023 is great\" → \" is great\").\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) #Removes characters like .,?! etc., using Python’s string translation.\n",
    "    tokens = word_tokenize(text) #Splits text into words (e.g., \"hello world\" → [\"hello\", \"world\"]).\n",
    "    tokens = [w for w in tokens if w not in stopwords.words('english')] #Removes common words like \"the\", \"is\", \"and\", which don’t add meaning in most contexts.\n",
    "\n",
    "    # Named Entity Replacement\n",
    "    ner_chunks = ne_chunk(pos_tag(tokens))\n",
    "    tokens = [\"NE\" if isinstance(chunk, nltk.Tree) else chunk[0] for chunk in ner_chunks]\n",
    "    #Identifies Named Entities (like \"Barack Obama\", \"New York\").\n",
    "    #Replaces each named entity with \"NE\" to generalize them.\n",
    "    #All other words are kept as-is.\n",
    "    #\"Barack Obama visited Paris\" → \"NE visit NE\"\n",
    "\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(w) for w in tokens]\n",
    "        #Reduces words to their root form.E.g., \"running\", \"runner\" → \"run\" using PorterStemmer\n",
    "\n",
    "    return ' '.join(tokens) #Returns the final list of cleaned words as a single string.\n",
    "\n",
    "# Sample documents\n",
    "texts = [\n",
    "    \"The Prime Minister visited the new development site in California.\",\n",
    "    \"Apple's iPhone 15 Pro was released yesterday and it broke all sales records.\",\n",
    "    \"The government passed a new policy that affects international students.\",\n",
    "    \"I love playing football and traveling to new cities.\",\n",
    "    \"He was awarded the Nobel Prize for his work on AI and robotics.\",\n",
    "    \"My weekend was relaxing and I read a good book.\",\n",
    "    \"The local sports team won the championship!\",\n",
    "    \"She presented a new AI model at the international conference.\",\n",
    "    \"I cooked a new recipe and it turned out delicious.\",\n",
    "    \"The United Nations released new climate goals for 2030.\"\n",
    "]\n",
    "labels = [1, 1, 1, 0, 1, 0, 0, 1, 0, 1] #You have 10 sentences, labeled as 1 (informative/news/policy) or 0 (personal/hobby).\n",
    "processed = [preprocess(doc) for doc in texts]\n",
    "#The output (processed) is:Normalized, consistent text\n",
    "#Easier to convert into numerical features (TF-IDF, embeddings), Less sparse due to stemming and NER\n",
    "#Free from noise like punctuation, numbers, and common words\n",
    "\n",
    "\n",
    "# ✅ TF-IDF + PCA\n",
    "#You're transforming a set of preprocessed text documents (processed) into numerical features using:\n",
    "#TF-IDF + PCA\n",
    "#Word2Vec + PCA\n",
    "#This helps you reduce dimensionality while preserving key semantic or statistical features, \n",
    "#which is essential for tasks like classification or clustering.\n",
    "\n",
    "def tfidf_pca(docs, labels, ngram=(1, 2), max_feats=50, components=3):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram, max_features=max_feats)\n",
    "    X = vectorizer.fit_transform(docs).toarray()\n",
    "    selector = SelectKBest(score_func=f_classif, k='all').fit(X, labels)\n",
    "    X_selected = selector.transform(X)\n",
    "    pca = PCA(n_components=min(components, X_selected.shape[1]))\n",
    "    return pca.fit_transform(X_selected)\n",
    "\n",
    "X_tfidf = tfidf_pca(processed, labels)\n",
    "\n",
    "#TF-IDF Vectorization\n",
    "#Converts text into a document-term matrix based on n-grams (default: unigrams and bigrams).\n",
    "#Limits vocabulary to max_feats=50.\n",
    "#SelectKBest\n",
    "#Uses ANOVA F-test (f_classif) to select all features that are statistically relevant to the labels.\n",
    "#It's a placeholder for potential feature filtering (e.g., top-k features).\n",
    "#PCA (Principal Component Analysis)\n",
    "#Reduces feature space to components=3, while preserving the most variance.\n",
    "\n",
    "# ✅ WORD2VEC + PCA\n",
    "\n",
    "def word2vec_pca(docs, size=50, components=3):\n",
    "    tokenized = [word_tokenize(doc) for doc in docs]\n",
    "    model = Word2Vec(sentences=tokenized, vector_size=size, window=5, min_count=1)\n",
    "    vecs = np.array([\n",
    "        np.mean([model.wv[w] for w in words if w in model.wv] or [np.zeros(size)], axis=0)\n",
    "        for words in tokenized\n",
    "    ])\n",
    "    return PCA(n_components=min(components, size)).fit_transform(vecs)\n",
    "\n",
    "X_w2v = word2vec_pca(processed)\n",
    "#Tokenization\n",
    "#Splits each sentence into words for Word2Vec training. Word2Vec Model\n",
    "#Trains a shallow neural network to learn word embeddings (vectors) of size 50.\n",
    "#Average Word Vectors\n",
    "#Averages all word vectors in each sentence to get a sentence-level embedding.\n",
    "#PCA- Reduces the vector space from 50D → 3D for easier use/visualization.\n",
    "\n",
    "# ✅ MODEL EVALUATION\n",
    "\n",
    "def evaluate(X, y, models, folds=3):\n",
    "    for name, model in models.items(): #Loops through each model and its name from the dictionary.\n",
    "        skf = StratifiedKFold(n_splits=folds) #Uses Stratified K-Fold Cross-Validation to preserve class distribution.Computes mean and standard deviation of model accuracy across folds.Useful for performance generalization across the dataset.\n",
    "        acc = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "        print(f\"{name} | Accuracy: {acc.mean():.4f} ± {acc.std():.4f}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y) #Splits the dataset into 60% training and 40% testing.Trains the model and makes predictions on the test set.\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"--- {name} Report ---\\n{classification_report(y_test, y_pred)}\") #Prints precision, recall, F1-score, and support for each class.\n",
    "#You're evaluating multiple machine learning models (Naive Bayes, Logistic Regression, and SVM) on two different feature representations:\n",
    "#X_tfidf: TF-IDF + PCA\n",
    "#X_w2v: Word2Vec + PCA\n",
    "#The function evaluate() performs cross-validation, train-test split evaluation, and prints out accuracy and classification reports.\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(C=1.0, max_iter=200),\n",
    "    \"SVM (Linear)\": SVC(kernel='linear', C=1)\n",
    "}\n",
    "\n",
    "print(\"TF-IDF + PCA Evaluation:\")\n",
    "evaluate(X_tfidf, labels, models)\n",
    "\n",
    "print(\"\\nWord2Vec + PCA Evaluation:\")\n",
    "evaluate(X_w2v, labels, models)\n",
    "#This code evaluates multiple classification models using both TF-IDF and Word2Vec text representations, reduced via PCA.\n",
    "#It uses Stratified K-Fold cross-validation to measure model accuracy stability and\n",
    "#also performs a single train-test split to generate detailed performance metrics like precision, recall, and F1-score. \n",
    "#This dual evaluation approach gives a balanced understanding of how each model performs and generalizes across different feature\n",
    "#sets — helping you decide which combination of vectorization and model yields the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The evaluation results show that among the tested models, Naive Bayes consistently outperformed Logistic Regression\n",
    "#and SVM (Linear) for both TF-IDF + PCA and Word2Vec + PCA representations, achieving the highest cross-validation accuracy\n",
    "#of 88.89% with TF-IDF features and 72.22% with Word2Vec. While Naive Bayes showed balanced precision and recall, \n",
    "#Logistic Regression and SVM struggled particularly with class 0, yielding 0.00 precision and recall, \n",
    "#indicating they failed to identify any instances of that class in the test set.\n",
    "#Across both vectorization strategies, Logistic Regression and SVM models displayed high bias towards class 1, \n",
    "#leading to 50% accuracy with lower F1-scores and unreliable predictions. \n",
    "#These results highlight that Naive Bayes is more robust in small and imbalanced datasets, \n",
    "#especially after dimensionality reduction, whereas linear models may require more data or regularization\n",
    "#to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
